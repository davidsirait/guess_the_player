{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6dd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "from twisted.internet import reactor, defer\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "\n",
    "from scrapy.utils.project import get_project_settings\n",
    "from scrapy.settings import Settings\n",
    "import yaml\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cc240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_file=\"config.yml\"):\n",
    "\t\"\"\"Read project configuration from a yaml file.\n",
    "\n",
    "\tArgs:\n",
    "\t\t\tconfig_file (str, optional): Path to the config file. Defaults to \"config.yml\".\n",
    "\n",
    "\tReturns:\n",
    "\t\t\tDict: The parsed config in a python dict\n",
    "\t\"\"\"\n",
    "\twith open(config_file) as config_file:\n",
    "\t\tconfig = yaml.load(config_file, yaml.Loader)\n",
    "\t\treturn config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31f60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config from config.yaml file\n",
    "config = read_config(\"../config.yaml\")['acquire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cb5ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_settings = get_project_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f646d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scrapy_config': {'USER_AGENT': 'guess-the-player/1.0 (https://github.com/davidsirait/guess-the-player)',\n",
       "  'FEED_URI_PARAMS': 'tfmkt.utils.uri_params',\n",
       "  'FEEDS': {'data/raw/transfermarkt-scraper/%(season)s/%(name)s.json.gz': {'format': 'jsonlines',\n",
       "    'postprocessing': ['scrapy.extensions.postprocessing.GzipPlugin']}},\n",
       "  'SPIDER_MODULES': ['tfmkt'],\n",
       "  'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
       "  'HTTPCACHE_ENABLED': True}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrapy_config():\n",
    "  \"\"\"Instantiate scrappy settings for the acquiring run.\n",
    "\n",
    "  Returns:\n",
    "      Settings: The default scrapy settings instance + overrides in config.yml\n",
    "  \"\"\"\n",
    "  # https://github.com/scrapy/scrapy/blob/master/scrapy/utils/project.py#L61\n",
    "  default_settings = get_project_settings()\n",
    "  overrides = acquire_config[\"scrapy_config\"]\n",
    "\n",
    "  default_settings.setdict(overrides)\n",
    "    \n",
    "  return default_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b643918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Asset():\n",
    "  \"\"\"A wrapper for the asset to be acquired.\n",
    "  It contains some useful methods for manipulating the assets, such as path and parents rendering.\n",
    "  \"\"\"\n",
    "  asset_parents = {\n",
    "      'competitions' : None,\n",
    "      'games': 'competitions',\n",
    "      'clubs': 'competitions',\n",
    "      'players': 'clubs',\n",
    "      'appearances': 'players',\n",
    "      'game_lineups': 'games'\n",
    "    }\n",
    "  \n",
    "  def __init__(self, name) -> None:\n",
    "\n",
    "    self.name = name\n",
    "    self.parent = None\n",
    "\n",
    "  def set_parent(self):\n",
    "    \"\"\"Get the parent of this asset as a new Asset\"\"\"\n",
    "\n",
    "    self.parent = Asset(self.asset_parents[self.name])\n",
    "  \n",
    "  def file_path(self, season):\n",
    "    if self.name == 'competitions':\n",
    "      return pathlib.Path(f\"data/competitions.json\")\n",
    "    else:\n",
    "      return pathlib.Path(f\"data/raw/transfermarkt-scraper/{season}/{self.name}.json.gz\")\n",
    "  \n",
    "  def file_full_path(self, season):\n",
    "    return str(self.file_path(season).absolute())\n",
    "\n",
    "  @classmethod\n",
    "  def all(self):\n",
    "    \"\"\"Get an ordered list of assets to be acquired.\n",
    "    Asset acquisition have dependecies between each other. This list returns the right order for asset\n",
    "    acquisition steps to run.\n",
    "    \"\"\"\n",
    "    assets = [Asset(name) for name in self.asset_parents if name != 'competitions']\n",
    "    for asset in assets:\n",
    "      asset.set_parent()\n",
    "    return assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d340c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_on_local(asset, seasons):\n",
    "\n",
    "  def assets_list(assets: str) -> List[Asset]:\n",
    "    \"\"\"Generate the ordered list of Assets to be scraped based on the provided string.\n",
    "\n",
    "    Args:\n",
    "        assets (str): A string representing the assets to be scraped.\n",
    "\n",
    "    Returns:\n",
    "        List[Asset]: The ordered list of assets to be scraped.\n",
    "    \"\"\"\n",
    "\n",
    "    if asset == 'all':\n",
    "      assets = Asset.all()\n",
    "    else:\n",
    "      asset_obj = Asset(name=asset)\n",
    "      asset_obj.set_parent()\n",
    "      assets = [asset_obj]\n",
    "    \n",
    "    return assets\n",
    "\n",
    "  def issue_crawlers_and_wait(assets, seasons, settings):\n",
    "    \"\"\"Create and submit scrapy crawlers to the reactor, and block until they've completed.\n",
    "\n",
    "    Args:\n",
    "        assets (List[Asset]): List of assets to be scraped.\n",
    "        seasons (List[int]): List of season to be scraped.\n",
    "        settings (dict): Crawler setting.\n",
    "    \"\"\"\n",
    "\n",
    "    # https://docs.scrapy.org/en/latest/topics/practices.html#running-multiple-spiders-in-the-same-process\n",
    "\n",
    "    runner = CrawlerRunner(settings)\n",
    "\n",
    "    # https://twistedmatrix.com/documents/13.2.0/api/twisted.internet.defer.inlineCallbacks.html\n",
    "    @defer.inlineCallbacks\n",
    "    def crawl():\n",
    "      for season in seasons:\n",
    "        # if there's no path created yet for this season create one\n",
    "        season_path = pathlib.Path(f\"data/raw/transfermarkt-scraper/{season}\")\n",
    "        if not season_path.exists():\n",
    "          season_path.mkdir(parents=True)\n",
    "\n",
    "        for asset_obj in assets:\n",
    "          # TODO: ideally, let transfermark-scraper handle destination file truncation via a setting instead of doing it here\n",
    "          # checkout https://foroayuda.es/scrapy-sobrescribe-los-archivos-json-en-lugar-de-agregar-el-archivo/\n",
    "          file_path = asset_obj.file_path(season)\n",
    "          if file_path.exists():\n",
    "            os.remove(str(file_path))\n",
    "          logging.info(\n",
    "            f\"Schedule {asset_obj.name} for season {season}\"\n",
    "          )\n",
    "          yield runner.crawl(\n",
    "            asset_obj.name,\n",
    "            parents=asset_obj.parent.file_full_path(season),\n",
    "            season=season\n",
    "          )\n",
    "\n",
    "      reactor.stop()\n",
    "    \n",
    "    crawl()\n",
    "    reactor.run()\n",
    "  \n",
    "  # get seasons and assets list\n",
    "  expanded_seasons = seasons_list(seasons)\n",
    "  expanded_assets = assets_list(asset)\n",
    "\n",
    "  # define crawler settings\n",
    "  settings = scrapy_config()\n",
    "  \n",
    "  # create crawlers and wait until they complete\n",
    "  issue_crawlers_and_wait(expanded_assets, expanded_seasons, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea93c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674da6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f6c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685ec78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620de2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
